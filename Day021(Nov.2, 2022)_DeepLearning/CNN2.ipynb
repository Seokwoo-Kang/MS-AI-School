{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P8SEvV6kCIQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil  #네임 스페이스 추가 : cmd (shell util 명령어를 사용하기 위해)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcHAPKh-kJ8F"
      },
      "outputs": [],
      "source": [
        "# 이미지를 처리하는 작업\n",
        "# Original Data Path\n",
        "# 현재 디렉토리 : './'\n",
        "original_dataset_dir = './datasets/train'\n",
        "\n",
        "# 저안의 이미지 데이터를 쪼개서 훈련용, 검증용, 테스트용으로 나눔\n",
        "\n",
        "# Small Dataset Path\n",
        "base_dir = './datasets/cats_and_dogs_small'\n",
        "\n",
        "# 있으면 지우고 새로만들기\n",
        "if os.path.exists(base_dir):\n",
        "    shutil.rmtree(base_dir)     # retree 지우기\n",
        "\n",
        "os.mkdir(base_dir)    # mkdir 새로만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZR5r7Iw7kJ5y"
      },
      "outputs": [],
      "source": [
        "# Train, Validation, Test data로 나누어 만들기\n",
        "# 2개의 경로를 하나로 합칠때\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJWsqpDukJ3y"
      },
      "outputs": [],
      "source": [
        "# 각 폴더마다 이미지 데이터 넣기\n",
        "\n",
        "# 필요한 경로 설정\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "\n",
        "os.mkdir(train_cats_dir)\n",
        "os.mkdir(train_dogs_dir)\n",
        "os.mkdir(validation_cats_dir)\n",
        "os.mkdir(validation_dogs_dir)\n",
        "os.mkdir(test_cats_dir)\n",
        "os.mkdir(test_dogs_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KeBZVkvkJ1k"
      },
      "outputs": [],
      "source": [
        "# File copy작업\n",
        "# ++이미지 파일 이름 바꾸는 것도 가능\n",
        "fnames = []\n",
        "for i in range(1000): # print(i) : 0부터 999까지\n",
        "    filename = 'cat.{}.jpg'.format(i)\n",
        "    fnames.append(filename)    \n",
        "print(fnames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bn3301x9kJzS"
      },
      "outputs": [],
      "source": [
        "# 한줄로 표현\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZGh3-gvkJxS"
      },
      "outputs": [],
      "source": [
        "# cats train data copy\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)    # 원본 경로 잡기\n",
        "    dst = os.path.join(train_cats_dir, fname)          # 복사할 폴더 경로 잡기\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "# dogs train data copy\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)    # 원본 경로 잡기\n",
        "    dst = os.path.join(train_dogs_dir, fname)          # 복사할 폴더 경로 잡기\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "print('----------------- Copy Completed------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVZcZZMQkJvF"
      },
      "outputs": [],
      "source": [
        "# cats validation data copy\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000,1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)    # 원본 경로 잡기\n",
        "    dst = os.path.join(validation_cats_dir, fname)     # 복사할 폴더 경로 잡기\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "# dogs validation data copy\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000,1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)    # 원본 경로 잡기\n",
        "    dst = os.path.join(validation_dogs_dir, fname)     # 복사할 폴더 경로 잡기\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "print('----------------- Copy Completed------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XZ9VCLMkJsy"
      },
      "outputs": [],
      "source": [
        "# cats test data copy\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500,2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)    # 원본 경로 잡기\n",
        "    dst = os.path.join(test_cats_dir, fname)           # 복사할 폴더 경로 잡기\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "# dogs test data copy\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1500,2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)    # 원본 경로 잡기\n",
        "    dst = os.path.join(test_dogs_dir, fname)           # 복사할 폴더 경로 잡기\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "print('----------------- Copy Completed------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70D9YkfckJqa"
      },
      "outputs": [],
      "source": [
        "# 복사 확인 코드\n",
        "\n",
        "# print('Train cat images: ', os.listdir(train_cats_dir))       # os.listdir() 지정된 경로내의 파일 목록\n",
        "print('Train cat images: ', len(os.listdir(train_cats_dir)))    # len(os.listdir()) 지정된 경로내의 파일 갯수\n",
        "print('Train dog images: ', len(os.listdir(train_dogs_dir)))\n",
        "print('Validation cat images: ', len(os.listdir(validation_cats_dir)))\n",
        "print('Validation dog images: ', len(os.listdir(validation_dogs_dir)))    \n",
        "print('Test cat images: ', len(os.listdir(test_cats_dir)))\n",
        "print('Test dog images: ', len(os.listdir(test_dogs_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h68TpdZakJoS"
      },
      "outputs": [],
      "source": [
        "# Build Network\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu', input_shape = (150,150,3)))     # input_shape = (150,150,3) 맨뒤에 3은 이미지가 컬러이기 떄문에\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))                                               # Conv2D는 특징을 잡고 Maxpooling2D는 필터역할\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))   \n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512,activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjKmyNFlkJmC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model.compile(optimizer= 'rmsprop',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy']\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0LSS64akJcS"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "# tensor로 만드는 방법\n",
        "# Image Scaling 이미지 스케일 동일하게 조정\n",
        "\n",
        "# *****test 가 아니라 validation 으로 다 고쳐야함*******\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)          # tensor 바꿔줌 1을 기준으로 데이터 정제\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)           # tensor로 바꾸기위해 1.(소수점) 255사이즈로 조정하겠다\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                                            train_dir,\n",
        "                                            target_size = ( 150, 150 ),   # 150x150짜리로\n",
        "                                            batch_size = 20,              # 20개 단위로 데이터를 던지겠다(변환하겠다)\n",
        "                                            class_mode = 'binary'         # 둘중 한개 선택\n",
        "                                            )\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(                        \n",
        "                                            validation_dir,\n",
        "                                            target_size = ( 150, 150 ),   # 150x150짜리로\n",
        "                                            batch_size = 20,\n",
        "                                            class_mode = 'binary'         # 둘중 한개 선택\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzkWOHkzkhR6"
      },
      "outputs": [],
      "source": [
        "# tensor로 나왔는지 확인\n",
        "train_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ENXo02wkhPr"
      },
      "outputs": [],
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('Batch Data Size: ', data_batch.shape)\n",
        "    print('Batch Labels Size', labels_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKoqLv0vkhNc"
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 100,               # epoch 한번에 이미지 100개 단위로 돌림, 결과도 100개 단위로 계산됨, 결국 100개 단위로 처리\n",
        "    epochs = 30,\n",
        "    validation_data = test_generator,\n",
        "    validation_steps = 50                 # vlaidation 50개 단위로 검증    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDvUnsE3khLU"
      },
      "outputs": [],
      "source": [
        "model.save('cats_and_dogs_small_1.0.h5')    # keras 파일은 .h5 확장자\n",
        "import matplotlib.pyplot as plt\n",
        "# 데이터 시각화\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc)+1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b-', label='Validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validaion loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy18I0oykhJP"
      },
      "outputs": [],
      "source": [
        "# 데이터 증식\n",
        "data = ImageDataGenerator(\n",
        "    rotation_range = 40,        # 40% 정도 돌림\n",
        "    width_shift_range = 0.2,    # 좌우로 20% 정도 이동\n",
        "    height_shift_range = 0.2,    # 상하로 20% 정도 이동\n",
        "    shear_range = 0.2,          # 20% 정도 기울임\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,     # 좌우반전\n",
        "    fill_mode = 'nearest'       # 빈칸 채우기 : 근처에 있는 값\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvUC3IqUkhG7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "fnames = sorted([os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)])\n",
        "img_path = fnames[3]\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "x = image.img_to_array(img) # 이미지의 x 좌표\n",
        "x = x.reshape((1,)+ x.shape)\n",
        "\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1):\n",
        "    plt.figure(i)\n",
        "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i%4 ==0:\n",
        "        break\n",
        "        \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-16mH4pkhEz"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(    \n",
        "    rescale=1./255,    \n",
        "    rotation_range=40,    \n",
        "    width_shift_range=0.2,    \n",
        "    height_shift_range=0.2,    \n",
        "    shear_range=0.2,    \n",
        "    zoom_range=0.2,    \n",
        "    horizontal_flip=True,)\n",
        "# 검증 데이터는 증식되어서는 안 됩니다!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(       \n",
        "    # 타깃 디렉터리        \n",
        "    train_dir,       \n",
        "    # 모든 이미지를 150 × 150 크기로 바꿉니다        \n",
        "    target_size=(150, 150),        \n",
        "    batch_size=32,       \n",
        "    # binary_crossentropy 손실을 사용하기 때문에 이진 레이블을 만들어야 합니다        \n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=10,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xTnQe8RkhCr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkqhuH8skhAa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u4cpMi_kg-K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJFFOZankg2r"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
