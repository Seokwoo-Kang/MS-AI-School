# 11월 15일 수업 11시부터

## Azure Cosmos DB 실습
Azure 포탈에서 본인 리소스그룹에 들어가 '+ 만들기' -> Azure Cosmos DB 검색 -> 만들기   
앞서 보았던 API를 선택하는 부분이 나오는데 가장 처음에 나오는 SQL로 설정

만들고 나서 사용하기 위해서는 Azure Storage Account의 Blob이나 FileShare처럼 컨테이너를 만들어줘야함. '+ 컨테이너추가'를 누르고 Database id 에 'loginData' Container id에 'container1'입력.   
throughput이라는 부분이 있는데 autoscale로 하면 지정한 RU보다 데이터가 많이 들어오면 자동으로 한계를 늘림.(초당 처리량) Manual로 설정하면 지정한 RU만큼만 데이터를 처리. autoscale로 하면 속도는 빠르지만 비쌈. 한번 늘어난 한계는 시간이 지나면 원래대로 돌아옴. 초당 처리량은 바로 아래('Database Max RU/s')에서 설정 가능.

왼쪽 메뉴에서 '전역으로 데이터 복제'를 선택해 전시간에 이야기한 DB를 복제하는 기능을 확인 가능. 다중 지역 쓰기를 활성화하면 여러 지역에서 동시에 쓰기 기능 사용 가능.   
지역을 하나 늘릴 때마다 돈.   
기능을 확인만 하고 활성화는 하지않음.

<!-- 아래부터는 하나하나 깊게 들어가면 시간이 오래걸리는 개념들이라 문제를 풀정도만 보고 넘어간다고 하심 -->

## Azure Data Factory

공장의 컨베이어밸트 개념, 데이터가 들어오면 컨베이어밸트를 따라 각각의 데이터에 지정한 작업이 이루어짐.   
데이터가 들어오는 통로를 파이프라인이라고 부름. 한군데가 아닌 여러 곳에서 데이터가 들어오고 이 데이터를 한꺼번에 모아서 데이터 팩토리에서 가공.   
데이터 분석보다는 데이터를 받아서 다음 단계로 넘겨주기 위해 준비하는 과정

## Azure Data Lake Storage

공장에서 생산된 상품은 창고(warehouse)에 저장함. 데이터를 팩토리를 통과한 데이터 역시 이러한 창고에 저장되는데 그러한 창고의 기능을 하는 것 중 하나가 Data Lake(저수지).

Azure Data Lake Storage는 Azure에서 제공하는 Data Lake 서비스.   
파일에 접근하기 위해서는 권한을 설정할 필요가 있는데 권한 설정 방법으로 POSIX와 RBAC 두가지를 제공. 두가지 다 알고있으면 좋음(설명은 하나만 해주심)
POSIX, 유닉스에서 권한을 설정하는 표준, 리눅스는 유닉스를 따라했기 때문에 리눅스에서도 POSIX를 기본으로 사용.

<!-- (딴소리)최초의 유닉스는 AT&T에서 만들었다. C언어로 한땀한땀만든 운영체제. AT&T는 전화기만든 벨이 세운 회사인데 아직도 살아있다. 너무 거대해서 반독점법으로 6조각남. 과거에는 전화기가 가장 최신 기술이었고 따라서 통신회사에서 혁신이 많이 발생했다. 전화기 다음으로는 사무용품, 복사기 만드는 회사 같은거 -->

Hadoop도 호환이 된다. Hadoop은 코끼리를 로고로 사용하는데 큰 작업에 많이 사용하는 프로그램이라 정해진 로고. APACHE 재단이 붙어있기 때문에 공개 소프트웨어.   
분산파일시스템이라고 하는데 분석해야하는 데이터를 나누어 분석하는 것.   
예를 들어 1000기가바이트의 데이터가 있는데 이를 하나의 서버 컴퓨터로 분석하려면 1000시간이 소모. 시간을 줄이기 위해서는 서버를 늘리면 된다. 2대를 쓰면 500시간, 4대를 쓰면 250시간... 이렇게 큰 데이터가 들어오면 데이터를 나눈 후 따로 처리하고 다시 한명에게 몰아주는 처리 방식, 팀플과 유사. 사용하는 컴퓨터 하나하나를 노드라고 부른다. 빅데이터를 분석할 때 많이 사용됨.   
데이터 분석을 위해서는 저장을 해야하고 이를 위해 Azure Data Lake Storage를 사용할 수 있다.

<!-- 오후 수업 시작 -->

## Azure Data Bricks

Azure가 없는 Databricks도 존재, 클라우드에 올라오면서 Azure가 붙음. 12월에 Databricks 세미나 행사가 있으니 시간나면 확인.   
Apache Spark를 기반으로 만들어짐. 데이터를 다루는 도구의 모음? 같은 느낌.   
파이프라인으로 원본 데이터가 들어오면 데이터 팩토리를 거쳐서 1차 가공되어 데이터브릭스로 이동한다. 데이터브릭스에서는 데이터를 정리하거나 필요한 부분만 추출하거나 필요하다면 머신러닝을 돌리는 등 필요한 데이터로 재단하여 스토리지로 넘겨준다. Azure Data Bricks의 경우 Azure의 각종 서비스로 데이터를 보낼 수 있다. 데이터 시각화를 위해 Power BI로 보낼 수도 있다.   

데이터를 다루기 위한 작업 영역이 존재한다. 작업 영역에서는 SQL 구문을 통해 구동된다.   
기계적으로 데이터를 자르고 붙이는 기능 뿐 아니라 데이터를 분석하고 예측, 판단하는 기능도 외부 AI 서비스를 사용하지 않고 Databricks 내에서 처리할 수 있다. 이러한 기능을 위해 고유 컴퓨팅 자원을 가지고있다.(런타임)
일종의 데이터큐브와같은 역할을 한다.

설명만으로는 이해하기 어려워서 추후 실습을 할 수도 있다.

## Azure Analysis Service

분석서비스, 데이터 수집, 저장, 분석을 합친 전체 과정
Azure Synapse라는 서비스가 나오는데 분석을 위한 데이터 저장소 서비스
분석 후 시각화 할 때 Power BI 사용

## Azure HDInsight

HD는 Hadoop의 약자, Hadoop을 클라우드에 올려놓은 서비스.
Hadoop을 사용하는 빅데이터의 예시, DNA, SNS 등의 데이터
Hadoop을 세팅하기 위해서는 최소 서버 4대가 필요. 유지 관리비가 많이들기 때문에 빅데이터 분석을 매일매일 사용하는 업종이 아닌 이상 클라우드에서 구축하는게 싸다.

## Azure 데이터 수집
생략. 필요할 때 다시 말씀하신다고 함


## Azure CLI 실습
작업을 위해서 가상머신 생성, windows 11 pro 21h2, 특이사항 없이 기본설정으로 생성 후 RDP를 사용해서 연결   
브라우저에서 Azure CLI 검색 후 설치   
설치 확인을 위해 cmd 실행 후 'az' 입력, 실행, 뭐가 주저리주저리 나오면 잘 설치된 것

Azure CLI, command line으로 Azure를 제어할 수 있는 도구
해리포터의 마법지팡이, 명령을 내리면 실행이 됨
az, Azure 명령의 약자 'az 상품명 명령어' 의 구조 
명령을 주는 주체를 알아야 하기 때문에 login부터 실행
'az login' 하면 브라우저 나와서 로그인, 제대로 실행이 되면 결과를 JSON형태로 리턴한다(공통)
'az vm list', 생성된 vm의 리스트 확인
'az group list', 생성된 리소스 그룹 리스트 확인
'az group create --name RGTest{본인번호} --location eastus' 리소스 그룹 만들기

가상머신 만들기, 가상네트워크를 먼저 만들고 가상머신에 끼워주는 방식으로
```shell
az network vnet create --name labuser{본인번호}vnet --resource-group {아까만든리소스그룹} --subnet-name labuser{본인번호}subnet --address-prefixes 10.0.0.0/16 --subnet-prefixes 10.0.0.0/24
```
순서대로 가상네트워크이름, 리소스그룹, 서브넷이름, prefixes, 서브넷 prefixes 지정

```shell
az vm create --resource-group {리소스그룹} --name labuser{본인번호}testvm --image UbuntuLTS --vnet-name {가상네트워크이름} --subnet labuser11subnet {서브넷이름} --generate-ssh-keys
```
순서대로 리소스그룹, 가상머신이름, 이미지(버전을 지정 안하면 보통 최신버전), 가상네트워크이름, 서브넷이름, ssh keyfile 생성
ssh keyfile이 있으면 파일로 인증을 하고 들어갈 수 있다.
'az vm show --name{가상머신이름} --resource-group {리소스그룹}'으로 만들어진 vm을 확인

만든 리소스들 삭제
'az group delete --name {리소스그룹}', 명령어 뒤에 --yes를 붙이면 y/n를 물어볼 때 자동으로 yes로 대답한다.

<!-- 명령어에서 '--'는 풀네임 '-'는 약어 예를들어 '--name', '-n' -->
<!-- 리눅스 명령어 &, 지정한 작업을 백그라운드로 진행 -->
```
az ad user delete --id "userid"
echo "USER 'id' DELETED."
az group delete --name "resourcename" --yes &
```
<!-- 선생님이 Azure계정 지우는 스크립트 -->

## Power BI

마이크로소프트에 Power Platform이라는 것이 있음. 여러가지 도구를 제공하는데 그 중 하나가 Power BI   
들어오는 데이터로 Dashboard를 만들어서 예쁘게 보여준다, 특정 항목을 선택하면 그 항목에 맞춰서 다른 항목들의 그래프가 바뀜   
Power BI desktop이라는 프로그램으로 대시보드 디자인이 가능하다.
Power BI 서비스를 사용해 만든 대시보드를 공유, 클라우드 기반
모바일 지원
보고서 작성 기능도 있다.
대시보드는 타일들로 구성.

<!-- 'low-code tool to adapt', low-code, no-code 유행, 코드를 적게 짜거나 안짜고 무언가를 수행하는 것 -->
<!-- Power BI 이외에도 다른 도구들 둘러봤음, 쉽게 App 만드는 PowerApps, 홈페이지 만드는 Power Pages, 자동화 기능을 만드는 Power Automate, 챗봇만드는 Power Virtural Agents -->

## AKS 실습

아까 사용했던 VM 계속 사용
```shell
az acr create --resource-group RG{본인번호} --name labuser{본인번호}acr --sku Basic
```
sku, 스쿠, 만드는 프로그램의 스팩   
ACR, azure container registry 생성, Docker container를 저장하는 곳   
예전에 Docker 실습할 때 container를 만들고 Docker Hub에 올린적이 있는데 Docker Hub같은 곳이 registry.   
Docker Hub의 경우 외부 사이트기 때문에 Container를 전송하는 일이나 보안 등의 문제가 있기 때문에 클라우드 상에 registry를 생성할 필요. 이를 위한게 ACR   
registry에 들어간 container를 쿠버네티스에 연결하면 쿠버네티스가 이를 pod에 넣고 배포하게 된다. Azure상에서 사용하는 쿠버네티스가 AKS   

AKS 생성
```shell
az aks create --resource-group RG{본인번호} --name labuser{본인번호}aks --location eastus --attach-acr {아까만든 acr이름} --generate-ssh-keys
```
쿠버네티스는 레지스트리와 연결되어야 한다. 마지막에 붉은글씨로 뭐라고 나오는데 무시하고 진행

이제 Docker와 쿠버네티스를 컨트롤하기 위해 KubeCTL을 설치한다.
'az aks install-cli', 뭔가 노랑글씨가 왕창나오면 성공이다.

그 다음에 명령을 위해 인증을 가져오는 과정
'az aks get-credentials --resource-group RG{본인번호} --name {아까만든 aks이름}'
스크립트를 실행하면 로컬에 파일이 생성되는데 이후 이 파일을 활용해 인증을 얻을 수 있다.

Docker 만들기
Docker를 쉽게 만들기 위해 git을 활용하므로 일단 가상머신에 git을 설치한다.
git 설치 이후 cmd 재시작
'git clone https://github.com/Azure-Samples/azure-voting-app-redis.git'

clone이 완료되었으면 'cd azure-voting-app-redis'를 입력해서 폴더로 이동 dir로 파일 확인
yaml 파일 등 확인 가능
'cd azure-vote'를 사용해 안에 있는 azure-vote 폴더로 이동 dir로 파일 확인
dockerfile을 통해서 컨테이너 생성 가능
```shell
az acr build --image azure-vote-front:v1 --registry {ACR이름} --file Dockerfile .
```
마지막에 점 빼먹지 말기, 파일 경로 역할
만들고 난 후 Azure 포탈에 가면 만들어진 repository를 확인할 수 있다. 만든 ACR에 들어가서 좌측 리포지토리 항목을 선택

쿠버네티스로 배포하기 위한 과정, 새로운 도구를 사용, helm 헬름, 쿠버네티스 배포 과정이 복잡해져서 소프트웨어로 나온것
https://github.com/helm/helm/releases 들어가서 'window amd 64' 클릭, 다운로드 후 압축해제
압축해제한 폴더에 있는 'helm' 파일을 C:/Users/{VM사용자id}/azure-voting-appredis/azure-vote 경로에 복사
cmd는 이미 같은 경로에 가있기 때문에 'helm' 이라고 입력했을 때 무언가 실행되면 정상적으로 된 것
<!-- 정석적인 사용방법은 아님, 원래는 system 어디에 넣거나 window를 안쓰고 linux로 하는게 정석 -->

yaml파일 작성
```
apiVersion: v2
name: azure-vote-front
description: A Helm chart for Kubernetes

dependencies:
  - name: redis
    version: 14.7.1
    repository: https://charts.bitnami.com/bitnami

...
# This is the version number of the application being deployed. This version number should be
# incremented each time you make changes to the application.
appVersion: v1
```
위 내용을 메모장에 복사하여 helm을 복사한 곳과 같은 경로에 'azure-vote-fromt.yml' 로 저장, 저장시 모든파일로 해주지 않으면 txt파일로 저장됨
저장했으면 cmd에서 dir을 입력해 파일이 잘 생성되었는지 확인

여기까지 했으면 다음 스크립트 각각 실행
```shell
helm create azure-vote-front
helm dependency update azure-vote-front
```
'cd azure-vote-front'로 이동하여 dir로 체크, Chart랑 yml파일이랑 이것저것 있다.

'notepad values.yaml'을 입력하면 메모장을 켜서 yaml파일을 수정할 수 있다.
image:
    repository: nginx 
에서 'nginx'를 'labuser{본인번호}acr/azure-vote-front' 로 수정한다.
그 하단 tag: "" 부분을 tag: "v1"으로 바꾼다

스크롤을 내려서 하단에
service:
    type: ClusterIP
를 찾아 'ClusterIP'를 'LoadBalancer'로 수정한다.

수정을 완료했으면 파일을 저장
cmd로 돌아와 cd ..을 해서 상위폴더로 돌아간 후
'helm install azure-vote-front azure-vote-front/' 스크립트를 실행
실행하게 되면 쿠버네티스를 통해서 배포된다. Azure 포탈에서 확인 가능 
생성한 aks에서 좌측 서비스 및 수신 탭 확인

원래 제대로 된거면 외부IP를 클릭하면 접속이 가능한데 뭔가 꼬여서 오늘은 안들어가짐

방금 실습 과정 참고
https://learn.microsoft.com/ko-kr/azure/aks/quickstart-helm?tabs=azure-cli

시간이 되면 다음 과정 자습
https://learn.microsoft.com/ko-kr/azure/aks/learn/quick-kubernetes-deploy-cli
이건 helm을 사용하지 않는 배포, 저녁먹고 한번씩 해보라고 말씀하심

## 막간 WSL 써보기
가상머신 계속 사용, 내컴퓨터 아니니까 이것저것 해보기 프로젝트
powershell을 관리자 권한으로 실행

'wsl --install' 을 입력해 wsl 설치, 
wsl은 windows subsystem for linux의 약자
윈도우에서 사용하는 linux인데 완벽하게 구현되지는 않음

wsl을 활성화 시킨 후 리눅스를 올린다. Microsoft store(작업표시줄에 있음)에 들어가서 ubuntu 검색, 22.04.1LTS 버전을 다운로드

가상머신에서는 안되는 것으로
관심있으면 아래 문서 참고하여 자습
https://learn.microsoft.com/ko-kr/windows/wsl/install

결론: 리눅스 가상머신을 만들어서 사용하자